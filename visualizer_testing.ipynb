{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import argparse\n",
    "import numpy as np\n",
    "import moviepy.editor as mpy\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "# the functionality of this model has changed slightly, need to modify parts of code which work with biggan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading audio \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"visualize.py\", line 177, in <module>\n",
      "    cv1[classes[p]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]\n",
      "IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n"
     ]
    }
   ],
   "source": [
    "!python visualize.py --song beethoven.mp3 --resolution 256 --duration 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://cdns-preview-d.dzcdn.net/stream/c-d0bfbdb54010987219eec31cc3017afe-1.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get input arguments when run from command line/bash\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--song\", required=True)\n",
    "# parser.add_argument(\"--resolution\", default='256')\n",
    "# parser.add_argument(\"--duration\", type=int, default='30')\n",
    "# parser.add_argument(\"--pitch_sensitivity\", type=int, default=220)\n",
    "# parser.add_argument(\"--tempo_sensitivity\", type=float, default=0.25)\n",
    "# parser.add_argument(\"--depth\", type=float, default=1)\n",
    "# parser.add_argument(\"--classes\", nargs='+', type=int)\n",
    "# parser.add_argument(\"--num_classes\", type=int, default=12)\n",
    "# parser.add_argument(\"--sort_classes_by_power\", type=int, default=0)\n",
    "# parser.add_argument(\"--jitter\", type=float, default=0.5)\n",
    "# parser.add_argument(\"--frame_length\", type=int, default=512)\n",
    "# parser.add_argument(\"--truncation\", type=float, default=1)\n",
    "# parser.add_argument(\"--smooth_factor\", type=int, default=20)\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=30)\n",
    "# parser.add_argument(\"--use_previous_classes\", type=int, default=0)\n",
    "# parser.add_argument(\"--use_previous_vectors\", type=int, default=0)\n",
    "# parser.add_argument(\"--output_file\", default=\"output.mp4\")\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading audio \n",
      "\n"
     ]
    }
   ],
   "source": [
    "song = 'beethoven.mp3'\n",
    "\n",
    "print('\\nReading audio \\n')\n",
    "y, sr = librosa.load(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set model name based on resolution\n",
    "model_name='biggan-deep-' + '256' #default value: 256\n",
    "\n",
    "frame_length=512 #default value: 512\n",
    "\n",
    "#set pitch sensitivity\n",
    "pitch_sensitivity=(300-220) * 512 / frame_length #default value: 220 \n",
    "\n",
    "#set tempo sensitivity\n",
    "tempo_sensitivity= 0.25 * frame_length / 512 #default value: 0.25\n",
    "\n",
    "#set depth\n",
    "depth=1 #default value: 1\n",
    "\n",
    "#set number of classes  \n",
    "num_classes=12 #default value: 12\n",
    "\n",
    "#set sort_classes_by_power    \n",
    "sort_classes_by_power=0 #default value: 0\n",
    "\n",
    "#set jitter\n",
    "jitter=0.5 #default value: 0.5\n",
    "    \n",
    "#set truncation\n",
    "truncation=1 #default value: 1\n",
    "\n",
    "#set batch size  \n",
    "batch_size=30 #default value: 30\n",
    "\n",
    "#set use_previous_classes\n",
    "use_previous_vectors=0 #default value 0 to initialize\n",
    "\n",
    "#set use_previous_vectors\n",
    "use_previous_classes=0 #default value 0 to initialize\n",
    "    \n",
    "#set output name\n",
    "outname='gan_' + song\n",
    "\n",
    "# #set smooth factor\n",
    "# if args.smooth_factor > 1:\n",
    "#     smooth_factor=int(args.smooth_factor * 512 / frame_length)\n",
    "# else:\n",
    "#     smooth_factor=args.smooth_factor\n",
    "smooth_factor = 20 #default value: 20\n",
    "\n",
    "#set duration\n",
    "duration = 30\n",
    "if duration:\n",
    "    seconds=duration\n",
    "    frame_lim=int(np.floor(seconds*22050/frame_length/batch_size))\n",
    "# else:\n",
    "#     frame_lim=int(np.floor(len(y)/sr*22050/frame_length/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = BigGAN.from_pretrained(model_name)\n",
    "\n",
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "\n",
    "\n",
    "#create spectrogram\n",
    "spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000, hop_length=frame_length)\n",
    "\n",
    "#get mean power at each time point\n",
    "specm=np.mean(spec,axis=0)\n",
    "\n",
    "#compute power gradient across time points\n",
    "gradm=np.gradient(specm)\n",
    "\n",
    "#set max to 1\n",
    "gradm=gradm/np.max(gradm)\n",
    "\n",
    "#set negative gradient time points to zero \n",
    "gradm = gradm.clip(min=0)\n",
    "    \n",
    "#normalize mean power between 0-1\n",
    "specm=(specm-np.min(specm))/np.ptp(specm)\n",
    "\n",
    "#create chromagram of pitches X time points\n",
    "chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=frame_length)\n",
    "\n",
    "#sort pitches by overall power ##np.argsort returns indices of how to sort the array, not the sorted array. \n",
    "chromasort=np.argsort(np.mean(chroma,axis=1))[::-1]\n",
    "\n",
    "# chromasort = np.sort(np.mean(chroma, axis = 1))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "\n",
    "classes = 12\n",
    "# if args.classes:\n",
    "#     classes=args.classes\n",
    "#     if len(classes) not in [12,num_classes]:\n",
    "#         raise ValueError(\"The number of classes entered in the --class argument must equal 12 or [num_classes] if specified\")\n",
    "    \n",
    "if use_previous_classes==1:\n",
    "    cvs=np.load('class_vectors.npy')\n",
    "    classes=list(np.where(cvs[0]>0)[0])\n",
    "    \n",
    "else: #select 12 random classes\n",
    "    cls1000=list(range(1000))\n",
    "    random.shuffle(cls1000)\n",
    "    classes=cls1000[:12]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if sort_classes_by_power==1:\n",
    "\n",
    "    classes=[classes[s] for s in np.argsort(chromasort[:num_classes])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize first class vector\n",
    "cv1=np.zeros(1000)\n",
    "for pi,p in enumerate(chromasort[:num_classes]):\n",
    "    \n",
    "    if num_classes < 12:\n",
    "        cv1[classes[pi]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]       \n",
    "    else:\n",
    "        cv1[classes[p]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]\n",
    "\n",
    "#initialize first noise vector\n",
    "nv1 = truncated_noise_sample(truncation=truncation)[0]\n",
    "\n",
    "#initialize list of class and noise vectors\n",
    "class_vectors=[cv1]\n",
    "noise_vectors=[nv1]\n",
    "\n",
    "#initialize previous vectors (will be used to track the previous frame)\n",
    "cvlast=cv1\n",
    "nvlast=nv1\n",
    "\n",
    "\n",
    "#initialize the direction of noise vector unit updates\n",
    "update_dir=np.zeros(128)\n",
    "for ni,n in enumerate(nv1):\n",
    "    if n<0:\n",
    "        update_dir[ni] = 1\n",
    "    else:\n",
    "        update_dir[ni] = -1\n",
    "\n",
    "\n",
    "#initialize noise unit update\n",
    "update_last=np.zeros(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                            | 90/2586 [00:00<00:02, 891.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating input vectors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2586/2586 [00:03<00:00, 860.26it/s]\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "\n",
    "\n",
    "#get new jitters\n",
    "def new_jitters(jitter):\n",
    "    jitters=np.zeros(128)\n",
    "    for j in range(128):\n",
    "        if random.uniform(0,1)<0.5:\n",
    "            jitters[j]=1\n",
    "        else:\n",
    "            jitters[j]=1-jitter        \n",
    "    return jitters\n",
    "\n",
    "\n",
    "#get new update directions\n",
    "def new_update_dir(nv2,update_dir):\n",
    "    for ni,n in enumerate(nv2):                  \n",
    "        if n >= 2*truncation - tempo_sensitivity:\n",
    "            update_dir[ni] = -1  \n",
    "                        \n",
    "        elif n < -2*truncation + tempo_sensitivity:\n",
    "            update_dir[ni] = 1   \n",
    "    return update_dir\n",
    "\n",
    "\n",
    "#smooth class vectors\n",
    "def smooth(class_vectors,smooth_factor):\n",
    "    \n",
    "    if smooth_factor==1:\n",
    "        return class_vectors\n",
    "    \n",
    "    class_vectors_terp=[]\n",
    "    for c in range(int(np.floor(len(class_vectors)/smooth_factor)-1)):  \n",
    "        ci=c*smooth_factor          \n",
    "        cva=np.mean(class_vectors[int(ci):int(ci)+smooth_factor],axis=0)\n",
    "        cvb=np.mean(class_vectors[int(ci)+smooth_factor:int(ci)+smooth_factor*2],axis=0)\n",
    "                    \n",
    "        for j in range(smooth_factor):                                 \n",
    "            cvc = cva*(1-j/(smooth_factor-1)) + cvb*(j/(smooth_factor-1))                                          \n",
    "            class_vectors_terp.append(cvc)\n",
    "            \n",
    "    return np.array(class_vectors_terp)\n",
    "\n",
    "\n",
    "#normalize class vector between 0-1\n",
    "def normalize_cv(cv2):\n",
    "    min_class_val = min(i for i in cv2 if i != 0)\n",
    "    for ci,c in enumerate(cv2):\n",
    "        if c==0:\n",
    "            cv2[ci]=min_class_val    \n",
    "    cv2=(cv2-min_class_val)/np.ptp(cv2) \n",
    "    \n",
    "    return cv2\n",
    "\n",
    "\n",
    "print('\\nGenerating input vectors \\n')\n",
    "\n",
    "for i in tqdm(range(len(gradm))):   \n",
    "    \n",
    "    #print progress\n",
    "    pass\n",
    "\n",
    "    #update jitter vector every 100 frames by setting ~half of noise vector units to lower sensitivity\n",
    "    if i%200==0:\n",
    "        jitters=new_jitters(jitter)\n",
    "\n",
    "    #get last noise vector\n",
    "    nv1=nvlast\n",
    "\n",
    "    #set noise vector update based on direction, sensitivity, jitter, and combination of overall power and gradient of power\n",
    "    update = np.array([tempo_sensitivity for k in range(128)]) * (gradm[i]+specm[i]) * update_dir * jitters \n",
    "    \n",
    "    #smooth the update with the previous update (to avoid overly sharp frame transitions)\n",
    "    update=(update+update_last*3)/4\n",
    "    \n",
    "    #set last update\n",
    "    update_last=update\n",
    "        \n",
    "    #update noise vector\n",
    "    nv2=nv1+update\n",
    "\n",
    "    #append to noise vectors\n",
    "    noise_vectors.append(nv2)\n",
    "    \n",
    "    #set last noise vector\n",
    "    nvlast=nv2\n",
    "                   \n",
    "    #update the direction of noise units\n",
    "    update_dir=new_update_dir(nv2,update_dir)\n",
    "\n",
    "    #get last class vector\n",
    "    cv1=cvlast\n",
    "    \n",
    "    #generate new class vector\n",
    "    cv2=np.zeros(1000)\n",
    "    for j in range(num_classes):\n",
    "        \n",
    "        cv2[classes[j]] = (cvlast[classes[j]] + ((chroma[chromasort[j]][i])/(pitch_sensitivity)))/(1+(1/((pitch_sensitivity))))\n",
    "\n",
    "    #if more than 6 classes, normalize new class vector between 0 and 1, else simply set max class val to 1\n",
    "    if num_classes > 6:\n",
    "        cv2=normalize_cv(cv2)\n",
    "    else:\n",
    "        cv2=cv2/np.max(cv2)\n",
    "    \n",
    "    #adjust depth    \n",
    "    cv2=cv2*depth\n",
    "    \n",
    "    #this prevents rare bugs where all classes are the same value\n",
    "    if np.std(cv2[np.where(cv2!=0)]) < 0.0000001:\n",
    "        cv2[classes[0]]=cv2[classes[0]]+0.01\n",
    "\n",
    "    #append new class vector\n",
    "    class_vectors.append(cv2)\n",
    "    \n",
    "    #set last class vector\n",
    "    cvlast=cv2\n",
    "\n",
    "\n",
    "#interpolate between class vectors of bin size [smooth_factor] to smooth frames \n",
    "class_vectors=smooth(class_vectors,smooth_factor)\n",
    "\n",
    "\n",
    "#check whether to use vectors from last run\n",
    "if use_previous_vectors==1:   \n",
    "    #load vectors from previous run\n",
    "    class_vectors=np.load('class_vectors.npy')\n",
    "    noise_vectors=np.load('noise_vectors.npy')\n",
    "else:\n",
    "    #save record of vectors for current video\n",
    "    np.save('class_vectors.npy',class_vectors)\n",
    "    np.save('noise_vectors.npy',noise_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating frames \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/43 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "########################################\n",
    "    \n",
    "\n",
    "#convert to Tensor\n",
    "noise_vectors = torch.Tensor(np.array(noise_vectors))      \n",
    "class_vectors = torch.Tensor(np.array(class_vectors))      \n",
    "\n",
    "\n",
    "#Generate frames in batches of batch_size\n",
    "\n",
    "print('\\n\\nGenerating frames \\n')\n",
    "\n",
    "#send to CUDA if running on GPU\n",
    "model=model.to(device)\n",
    "noise_vectors=noise_vectors.to(device)\n",
    "class_vectors=class_vectors.to(device)\n",
    "\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in tqdm(range(frame_lim)):\n",
    "    \n",
    "    #print progress\n",
    "    pass\n",
    "\n",
    "    if (i+1)*batch_size > len(class_vectors):\n",
    "        torch.cuda.empty_cache()\n",
    "        break\n",
    "    \n",
    "    #get batch\n",
    "    noise_vector=noise_vectors[i*batch_size:(i+1)*batch_size]\n",
    "    class_vector=class_vectors[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "    output_cpu=output.cpu().data.numpy()\n",
    "\n",
    "    #convert to image array and add to frames\n",
    "    for out in output_cpu:    \n",
    "        im=np.array(Image.fromarray(out))\n",
    "        frames.append(im)\n",
    "        \n",
    "    #empty cuda cache\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save video  \n",
    "aud = mpy.AudioFileClip(song, fps = 44100) \n",
    "\n",
    "if args.duration:\n",
    "    aud.duration=args.duration\n",
    "\n",
    "clip = mpy.ImageSequenceClip(frames, fps=22050/frame_length)\n",
    "clip = clip.set_audio(aud)\n",
    "clip.write_videofile(outname,audio_codec='aac')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
